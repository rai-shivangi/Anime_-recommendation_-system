# -*- coding: utf-8 -*-
"""Anime Recommendation system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TseFoTm2I9cyqi4e75txc9jAVUTeTgit
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

import warnings
warnings.filterwarnings('ignore')



anime = pd.read_csv("anime.csv")
rating = pd.read_csv("rating.csv")

anime.head()

anime.shape

anime.info()

anime.describe()

anime.isna().sum()

print("After Dropping, Null Values of Anime Dataset :")
anime.dropna(axis = 0, inplace = True)
anime.isna().sum()

rating.head()

rating.shape

rating.info()

rating.describe()

rating.isna().sum()

rating.drop_duplicates(keep='first',inplace=True)
rating.shape

"""<h1>MERGING ANIME AND RATING DATASETS<h1>"""

combined_data = pd.merge(anime,rating,on="anime_id",suffixes= [None, "_user"])
combined_data = combined_data.rename(columns={"rating_user": "user_rating"})
combined_data.head()

combined_data.shape

"""<h1>TOP ANIME"""

top_anime = combined_data.copy()
top_anime.drop_duplicates(subset ="name", keep = "first", inplace = True)
top_anime_temp1 = combined_data.sort_values(["members"],ascending=False)
top_anime_temp1.head()

"""<h1>ANIME CATEGORIES"""

top_anime_temp1["type"].value_counts()

data = combined_data.copy()
data["user_rating"].replace(to_replace = -1 , value = np.nan ,inplace=True)
data = data.dropna(axis = 0)
print("Null values after final pre-processing :")
data.isna().sum().to_frame()

"""Selecting users who have rated more than 50 animes"""

selected_users = data["user_id"].value_counts()
data = data[data["user_id"].isin(selected_users[selected_users >= 50].index)]

"""Creating a pivot table consisting of rows as title and columns as user id, which will further be used to create sparse matrix which can be very helpful in finding the cosine similarity"""

data_pivot_temp = data.pivot_table(index="name",columns="user_id",values="user_rating").fillna(0)
data_pivot_temp.head()

import re
def text_cleaning(text):
    text = re.sub(r'&quot;', '', text)
    text = re.sub(r'.hack//', '', text)
    text = re.sub(r'&#039;', '', text)
    text = re.sub(r'A&#039;s', '', text)
    text = re.sub(r'I&#039;', 'I\'', text)
    text = re.sub(r'&amp;', 'and', text)
    
    return text

data["name"] = data["name"].apply(text_cleaning)

data_pivot = data.pivot_table(index="name",columns="user_id",values="user_rating").fillna(0)
print("After Cleaning the animes names, let's see how it looks like.")
data_pivot.head()

from sklearn.feature_extraction.text import TfidfVectorizer

tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents="unicode", analyzer="word", token_pattern=r"\w{1,}", ngram_range=(1, 3), stop_words = "english")

rec_data = combined_data.copy()
rec_data.drop_duplicates(subset ="name", keep = "first", inplace = True)
rec_data.reset_index(drop = True, inplace = True)
genres = rec_data["genre"].str.split(", | , | ,").astype(str)
tfv_matrix = tfv.fit_transform(genres)

from sklearn.metrics.pairwise import sigmoid_kernel

sig = sigmoid_kernel(tfv_matrix, tfv_matrix)      # Computing sigmoid kernel

rec_indices = pd.Series(rec_data.index, index = rec_data["name"]).drop_duplicates()

anime_name = input("Enter your favourite movie name : ")



# Recommendation Function
def give_recommendation(title, sig = sig):
    idx = rec_indices[title] # Getting index corresponding to original_title

    sig_score = list(enumerate(sig[idx]))  # Getting pairwsie similarity scores 
    sig_score = sorted(sig_score, key=lambda x: x[1], reverse=True)
    sig_score = sig_score[1:11]
    anime_indices = [i[0] for i in sig_score]
     
    # Top 10 most similar movies
    rec_dic = {"No" : range(1,11), 
               "Anime Name" : anime["name"].iloc[anime_indices].values,
               "Rating" : anime["rating"].iloc[anime_indices].values}
    dataframe = pd.DataFrame(data = rec_dic)
    dataframe.set_index("No", inplace = True)

    print("Recommendations for {title} viewers :\n")
    
    return dataframe

give_recommendation("Naruto")

give_recommendation("Bungou Stray Dogs")

give_recommendation("One Punch Man")


list_of_all_titles = combined_data['name'].tolist()

import difflib
find_close_match = difflib.get_close_matches(anime_name, list_of_all_titles)

print(find_close_match)

close_match = find_close_match[0]
print(close_match)

give_recommendation(close_match)

def anime_recommendations():
  anime_name = input("Enter your favourite anime name : ")

  list_of_all_titles = combined_data['name'].tolist()

  find_close_match = difflib.get_close_matches(anime_name, list_of_all_titles)

  close_match = find_close_match[0]

  give_recommendation(close_match)